## Simon Julien, Allison Liu, Jackson Curry
In this report, we were interested in exploring a range of different applications of language modeling. We had the idea to explore models that were chained together in such a way that the output in one model could be used in another model. First, Simon would use a few shot learning and siamese network model to classifications of language and imaging without training large amounts of data in the model. Jackson's grammar model would predict if a sentence was gramatically correct or not (CoLA dataset). Finally, Allison's BERT Sentence Classification model would check if the outputted joke was gramatically correct. If not, we would generate another joke. We were not able to do do all we had hoped, because it involved having our models complete sequentially. We each explored models relevant and helpful to us completing our overarching goal, which are detailed in the notebook summaries below. In future reports, we plan to complete our "meme generating natural language tool".

* Simon: This week, alongside interacting with my partners, I implemented a few-shot learning model in a few ways. In class, I weas fascinated by the GPT-3 model from openAI so i first implemented GPTneo which is a similar model that is small enough to actually run on a real computer. Next, (in the same notebook), I implemented flair to perform simlar nlp few shot classification tasks but while generating some of my own model rather than just importing GPT-neo. I did this in a few variations. Finally, I wanted to dive into siamese network language modeling for few shot learning because it is a common way of performing similarity based few-shot learning. My initial intention was combine image processing and nlp for the first time in my work throughout this class to classify handwritten language into a language. I had trouble converting away from a tutorial with the new dataset, so was forced just to stick with the tutorial that uses siamese few shot to classify faces (a very standard application). For our idea for next week's meme project, this image processing will be very relevant!


* Jackson: This week worked on 2 main notebooks.  The first notebook was made by reading through and understanding documentation from the hugging face library.  In this notebook on compiling documentation from Hugging Face in order to create a few short model implementations using the pretrained models. From reading the documentation we compiled lists of:
1.Short implementations using pretrained models
2.Pairing which types of famous models are used for which types of NLP problems
3.Pairing which types of common benchmark datasets are used for which types of NLP problems
4.Documentation we have found helpful to use later
In the second notebook Jackson tweaked a notebook that Allison used in order to fine-tune the BERT model for a new downstream task (fine tuning using the CoLA dataset to determine whether sentences were grammatically correct or not)
Finally there were a large number of attempts and datasets that were worked with that we uploaded in a folder called "Failed Attempts and Future Datasets" (don't feel the need to look at/grade these files with this weeks report, but the rational for uploading is explained in the next sentence). Our goal for next week is to create a working meme generator, and most of these files are related to that project so we wanted to upload them to github to be shared for the start of next project!

* Allison: This week I worked in two notebooks. In the first notebook, I do EDA on an unbalanced airline search query dataset with the intention of doing intent classification. The ATIS dataset used has search queries related to airline travel and labels categorizing the intention of the user (flight, airfare, ground service, etc.). I briefly comment on the results of a simple LSTM network that was trained and posted in an article as a baseline to improve upon for BERT. 
* In the second notebook, I modify a BERT for Sentence Classification notebook originally written to classify whether sentences are grammatically correct to do BERT for intent classification for the ATIS dataset. After loading a pre-trained BERT model which already had a good understanding of English word representations, I was impressed how little extra training it took to produce a rather high-quality model to accomplish a specific task. My task was related to the overarching group goal, as I will use BERT applied to sentence classification to check the grammatical accuracy of Jackson's outputted jokes, and now I have a good sense of how to use the model.
